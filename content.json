{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/about/about.html"}],"posts":[{"title":"大数据介绍","text":"什么是大数据 大数据（BIG DATA），指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产（百度百科的定义） 在目前的业界尚未对大数据由清晰明确的定义, 它的第一次出现是在麦肯锡公司的报告中出现的, 在维基百科上的较为模糊的定义是很难运用软件的手段获取大量的内容信息, 对其处理后整理得出的数据集合。其他计算机学科的学者给出的定义是数据的尺度极为巨大, 常规的数据处理软件无法对数据识别、存储和应用的海量数据信息 数据单位1MB = 1024KB、1GB = 1024MB1TB = 1024GB、1PB = 1024TB 大数据的特征 容量（Volume）：数据的大小决定所考虑的数据的价值和潜在的信息； 种类（Variety）：数据类型的多样性； 速度（Velocity）：指获得数据的速度； 可变性（Variability）：妨碍了处理和有效地管理数据的过程。 真实性（Veracity）：数据的质量 复杂性（Complexity）：数据量巨大，来源多渠道 价值（value）：合理运用大数据，以低成本创造高价值 大数据学习路线 技术 工具 JAVA 面向对象的编程语言 Linux 类Unix操作系统 Hadoop生态圈 1、HDFS 解决存储问题存储极大数目的信息（terabytes or petabytes），将数据保存到大量的节点当中。支持很大单个文件。提供高可靠性，是指一个或多个节点故障，系统仍然可以继续工作提供数据快速访问 2、MapReduce 解决计算问题它有个特点就是不管多大的数据只要给它时间它就能把数据跑完，但是时间可能不是很快所以它叫数据的批处理 3、Yarn 资源调度器 4、ZooKeeper 分布式应用程序协调服务一般用于存储一些相互协作的一些信息 5、Flume 数据采集工具 6、Hive 基于Hadoop的数据仓库工具 7、Hbase 分布式应用程序协调服务一般用于存储一些相互协作的一些信息 8、Sqoop 数据传递工具，如将数据从关系型数据库导入Hive Scala 多范式编程语言、面向对象和函数式编程的特性 Spark 目前企业常用的批处理离线数据/实时计算引擎它是用来弥补基于MapReduce处理数据速度上的缺点，它很是流氓，直接将数据存在内存中 【注意】 MapReduce运行时也是需要将代码数据加载到内存中的，只不过Spark都是基于内存操作 Flink 目前最火的流式处理框架、既支持流处理、也支持批处理 Elasticsearch 大数据分布式弹性搜索引擎 起源 Google 在大数据方面的三大论文 （谷歌三宝）在github大的当前目录下三宝的介绍 Hadoop 三大发行版本 Apache、Cloudera、Hortonworks Apache版本最原始、最基础：适合零基础 大公司在用 Cloudera Cloudera’s DistributionIncluding Apache Hadoop 简称CDH中小型公司用、简单方便、自带可视化 Hortonworks 文档较好 注：Cloudera 和Hortonworks 在2018年10月，国庆期间宣布合并硬件要求内存 最大支持内存查询：win + R输入 wmic memphysical get maxcapacity计算 MaxCapacity/1024/1024GB 硬盘:500G+","link":"/2019/10/26/BigData/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BB%8B%E7%BB%8D/"},{"title":"hadoop序列化","text":"序列化介绍 序列化是一种将对象的状态信息转化成可以存储或者传输的过程不是某一种编程语言所独有的特性 Java序列化 Java通过实现Serializable接口 1234567import java. io.Serializable ;／＊＊定义一个可以序列化的 App 信息类. */public class Appinfo implements Serializable{ ／／序列化标识 private static final long serialVersionUID = 11 ;} Hadoop 不使用Java序列化原因 Java 自带的序列化机制占用内存空间大，额外的开销会导致速度降低，Hadoop对序列化的要求较高，需要保证序列化速度快、体积小、占用带宽低等特性 Hadoop 序列化机制是将对象序列化到流中，而 Java 序列化机制是不断创建新对象 Hadoop 序列化 在 Hadoop 序列化机制中，org.apache.hadoop.io包中定义了大量的可序列化对象均实现Wriable接口的两个函数， 12(1) write：将对象写入字节流：(2) readFields：从字节流中解析出对象。 优势1231. 减少垃圾回收：从流中反序列化数据到当前对象，重复使用当前对象，减少了垃圾回收GC ;2. 减少网络流量 ： 序列化和反序列化对象类型不变 ，因此可以只保存必要的数据来减少网络流量；3. 提升 I/O 效率 ： 由于序列化和反序列化的数据量减少了，配合Hadoop压缩机制，可以提升I/O效率。","link":"/2019/10/28/BigData/Hadoop/hadoop%E5%BA%8F%E5%88%97%E5%8C%96/"},{"title":"HDFS快照管理","text":"快照管理 快照相当于对目录做一个备份。并不会立即复制所有文件，而是指向同一个文件。当写入发生时，才会产生新文件。 快照影响 快照创建瞬间完成，所耗时间成本为O(1) 快照修改时才会使用额外的额外的内存空间，内存成本O(M),M表示修改过的文件或目录数 快照记录块和文件大小，不对DataNode中的块进行复制 说明：* 快照可以在HDFS任何目录下设置，一个目录最多容纳65536个并发快照 基本语法12345678（1）hdfs dfsadmin -allowSnapshot 路径 （功能描述：开启指定目录的快照功能）（2）hdfs dfsadmin -disallowSnapshot 路径 （功能描述：禁用指定目录的快照功能，默认是禁用）（3）hdfs dfs -createSnapshot 路径 （功能描述：对目录创建快照）（4）hdfs dfs -createSnapshot 路径 名称 （功能描述：指定名称创建快照）（5）hdfs dfs -renameSnapshot 路径 旧名称 新名称 （功能描述：重命名快照）（6）hdfs lsSnapshottableDir （功能描述：列出当前用户所有已快照目录）（7）hdfs snapshotDiff 路径1 路径2 （功能描述：比较两个快照目录的不同之处）（8）hdfs dfs -deleteSnapshot &lt;path&gt; &lt;snapshotName&gt; （功能描述：删除快照） 案例实操 开启/禁用指定目录的快照功能 指定创建目录的位置为 /tmp/snapshot(即快照的存储目录)，在指定目录之前必须创建目录，不然会报错 12hdfs dfsadmin -allowSnapshot /tmp/snapshot hdfs dfsadmin -disallowSnapshot /tmp/snapshot //禁用时，对应的目录不允许存在快照 对目录创建快照 只有被开启快照功能的目录才能创建快照 123hdfs dfs -createSnapshot /tmp/snapshot // 对目录创建快照hdfs dfs -createSnapshot /tmp/snapshot snapshot //重命名快照（注：快照是只读的，无法修改名）通过web访问hdfs://Master:9000/tmp/snapshot/.snapshot/s…..// 快照和源文件使用相同数据块 查看快照 12hdfs dfs -lsr /tmp/snapshot/.snapshot/ //查看快照目录的详细信息hdfs lsSnapshottableDir //查看所有允许快照的目录 更改快照名字 12345hdfs dfs -renameSnapshot /tmp/snapshot/ snapshot snapshot1 注：路径只是你创建得名字/tmp/snapshot，不要带后边得/tmp/snapshot/.snapshot/，不然会出现hdfs dfs -renameSnapshot /tmp/snapshot/.snapshot/ snapshot1 snapshotrenameSnapshot: Modification on a read-only snapshot is disallowed 比较两个快照目录的不同之处 1234[root@vmaster opt]# hdfs snapshotDiff /tmp/snapshot s1 s2Difference between snapshot s1 and snapshot s2 under directory /tmp/snapshot:M .+ ./p 符号的意义： 符号 含义 + 文件或者目录被创建 - 文件或目录被删除 M 文件或目录被修改 R 文件或目录被重命名 恢复快照 123451.自定义创建一个快照名：hdfs dfs -createSnapshot /HAHA1 snapshot12.展示原文件包含内容：Hadoop fs -ls /HAHA13.里面有五个文件、删除其中1~2个/HAHA1/.snapshot/snapshot14.回复快照：hdfs dfs -cp /HAHA1/.snapshot/snapshot1 /snapshot 删除快照 12dfs dfs -deleteSnapshot 快照目录 快照名称dfs dfs -deleteSnapshot /tmp/snapshot snapshot1","link":"/2019/10/26/BigData/Hadoop/HDFS/HDFS%E5%BF%AB%E7%85%A7/"},{"title":"MapReduce介绍","text":"MapReduce的定义 &emsp;&emsp;Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。&emsp;&emsp;Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。 MapReduce优缺点优点 MapReduce 易于编程。它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。 良好的扩展性。当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。 高容错性。MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由 Hadoop内部完成的。 适合PB级以上海量数据的离线处理。这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，MapReduce很难做到。缺点 MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。 实时计算。MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。 流式计算。流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。 DAG（有向图）计算。多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。 MapReduce核心思想 分布式的运算程序往往需要分成至少2个阶段。第一个阶段的maptask并发实例，完全并行运行，互不相干。 第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出。 MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行。 MapReduce进程 一个完整的mapreduce程序在分布式运行时有三类实例进程： MrAppMaster：负责整个程序的过程调度及状态协调。 MapTask：负责map阶段的整个数据处理流程。 ReduceTask：负责reduce阶段的整个数据处理流程。 MapReduce编程规范 用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端) Mapper阶段 12345（1）用户自定义的Mapper要继承自己的父类 （2）Mapper的输入数据是KV对的形式（KV的类型可自定义） （3）Mapper中的业务逻辑写在map()方法中 （4）Mapper的输出数据是KV对的形式（KV的类型可自定义） （5）map()方法（maptask进程）对每一个&lt;K,V&gt;调用一次 Reduce阶段 1234（1）用户自定义的Reducer要继承自己的父类 （2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV （3）Reducer的业务逻辑写在reduce()方法中 （4）Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法 第一代和第二代MapReduce的区别","link":"/2019/10/26/BigData/Hadoop/MapReduce/MapReduce%E4%BB%8B%E7%BB%8D/"},{"title":"BigData/Hadoop/Hadoop通信机制和内部协议","text":"Hadoop RPCRPC模型 通行模块： 请求-响应 Stub程序： 用于保证RPC的透明性。在客户端，不在本地调用，而是将请求信息通过网络模块发送给法服务器端，服务器接收后进行解码。服务器中，Stub程序依次进行 解码（请求的参数）、调用相应的服务过程、编码返回结果等处理 调度程序： 调度来自通行模块的请求信息，根据其中标识选一个Stub程序运行 客户程序： 请求发出者 服务过程： 请求接收者 一个RPC的旅游： 客户端以本地调用方式产生本地Stub程序 该Stub程序将函数调用信息按照网络通信模块的要求封装成消息包，并交给通信模块发送到远程服务器端。 远程服务器端接收此消息后，将此消息发送给相应的Stub程序 Stub程序拆封消息，形成被调过程要求的形式，并调用对应函数 服务端执行被调用函数，并将结果返回给Stub程序 Stub程序将此结果封装成消息，通过网络通信模块逐级地传送给客户程序。 RPC特性 透明性 调用过程就像本地调用，察觉不到它的经历 高性能 ：Hadoop各个系统（如HDFS、MapReduce、YARN等）均采用了Master/Slave结构，其中，Master实际上是一个RPC server，它负责响应集群中所有Slave发送的服务请求。RPC Server性能要求高，为的是能够让多个客户端并发方位 易用性/可控性 Hadoop系统不采用Java内嵌的RPC（RMI,Remote Method Invocation）框架的主要原因是RPC是Hadoop底层核心模块之一，需要满足易用性、高性能、轻量级等特性 RPC例子执行过程： CalculateClient对象本地调用产生Stub程序 经通信模块上传至服务器CalculateServer对象，在创建Server时设置了协议和业务逻辑（服务过程），处理过后根据上述RPC过程返回 客户端接收后打印到日志中 先定义一些常量 这里不需要太多的在意，直接使用在代码里面也行，在大的项目中为了使程序易于修改而这样设置 1234567891011/** * 静态变量声明类 */public interface Constants { public interface VersionID { public static final long RPC_VERSION = 7788L; } public static final String RPC_HOST = &quot;127.0.0.1&quot;; public static final int RPC_PORT = 8888;} 定义一个Service接口，协议类12345678910111213import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.ipc.ProtocolInfo;@ProtocolInfo(protocolName = &quot;&quot;, protocolVersion = Constants.VersionID.RPC_VERSION)public interface CalculateService { //真实业务逻辑，加减法， public IntWritable add(IntWritable a, IntWritable b); public IntWritable sub(IntWritable a, IntWritable b); public Text echo(Text mt);} @ProtocolInfo(protocolName = “”, protocolVersion = Constants.VersionID.RPC_VERSION) 没有这句就不能将该类设置为协议 Service接口的实现类1234567891011121314151617181920212223242526272829303132333435import java.io.IOException;public class CalculateServiceImpl implements CalculateService { /** * 该方法没有也行 * */ public ProtocolSignature getProtocolSignature(String arg0, long arg1, int arg2) throws IOException{ return this.getProtocolSignature(arg0, arg1, arg2); } /** * 校验hadoop RFC版本号 * @param arg0 * @param arg1 * @return */ public long getProtocolVersion(String arg0, long arg1) throws IOException { return Constants.VersionID.RPC_VERSION; } @Override public IntWritable add(IntWritable a, IntWritable b) { return new IntWritable(a.get() + b.get()); } @Override public IntWritable sub(IntWritable a, IntWritable b) { return new IntWritable(a.get() - b.get()); } @Override public Text echo(Text mt) { return mt; }} Server和Client类123456789101112131415161718192021222324252627282930import org.apache.hadoop.ipc.RPC;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;public class CalculateServer { private static final Logger LOG = LoggerFactory.getLogger(CalculateServer.class); public static void main(String[] args) { try { //构造Server,并设置协议接口，主机、端口，真实业务逻辑 RPC.Server server = new RPC.Builder(new Configuration()) .setProtocol(CalculateService.class) .setBindAddress(Constants.RPC_HOST) .setPort(Constants.RPC_PORT) .setInstance(new CalculateServiceImpl()) .build(); //启动Server server.start(); LOG.info(&quot;Server has Started!&quot;); } catch (IOException e) { LOG.error(&quot;Server has Error&quot;); } }} 123456789101112131415161718192021222324252627282930313233343536import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.ipc.RPC;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.IOException;import java.net.InetSocketAddress;public class CalculateClient { private static final Logger LOG = LoggerFactory.getLogger(CalculateServer.class); public static void main(String[] args) { //格式化IP和端口 InetSocketAddress addr = new InetSocketAddress(Constants.RPC_HOST, Constants.RPC_PORT); //校验Hadoop RPC版本号 long protocolVersion = RPC.getProtocolVersion(CalculateService.class); try { //获取Server连接 CalculateService proxy = RPC.getProxy(CalculateService.class, protocolVersion, addr, new Configuration()); IntWritable add = proxy.add(new IntWritable(1), new IntWritable(2)); IntWritable sub = proxy.add(new IntWritable(3), new IntWritable(2)); LOG.info(&quot;1+2 = &quot; + add); LOG.info(&quot;3-2 = &quot; + sub); } catch (IOException e) { LOG.error(&quot;Client has error!&quot;); } }} 注意： 查看本程序运行结果需要一个日志文件，如果不想加，把LOG的相关语句换为打印输出就行在resource文件夹下创建 log4j.properties 12345678log4j.rootLogger=INFO, stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n log4j.appender.logfile=org.apache.log4j.FileAppender log4j.appender.logfile.File=target/spring.log log4j.appender.logfile.layout=org.apache.log4j.PatternLayout log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n 客户端运行结果12342019-10-31 18:59:28,499 WARN [org.apache.hadoop.util.Shell] - Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems 2019-10-31 18:59:28,619 WARN [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 2019-10-31 18:59:29,734 INFO [hadooprfc.calculate.CalculateServer] - 1+2 = 3 2019-10-31 18:59:29,734 INFO [hadooprfc.calculate.CalculateServer] - 3-2 = 5","link":"/2019/10/30/BigData/Hadoop/Hadoop%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E5%92%8C%E5%86%85%E9%83%A8%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"什么是大数据","slug":"什么是大数据","link":"/tags/%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop序列化","slug":"hadoop序列化","link":"/tags/hadoop%E5%BA%8F%E5%88%97%E5%8C%96/"},{"name":"HDFS快照","slug":"HDFS快照","link":"/tags/HDFS%E5%BF%AB%E7%85%A7/"},{"name":"MapReduce介绍","slug":"MapReduce介绍","link":"/tags/MapReduce%E4%BB%8B%E7%BB%8D/"},{"name":"Hadoop RPC","slug":"Hadoop-RPC","link":"/tags/Hadoop-RPC/"},{"name":"Hadoop 通信机制","slug":"Hadoop-通信机制","link":"/tags/Hadoop-%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/"}],"categories":[{"name":"BigData","slug":"BigData","link":"/categories/BigData/"},{"name":"Hadoop","slug":"Hadoop","link":"/categories/Hadoop/"},{"name":"Hadoop","slug":"BigData/Hadoop","link":"/categories/BigData/Hadoop/"},{"name":"HDFS","slug":"BigData/Hadoop/HDFS","link":"/categories/BigData/Hadoop/HDFS/"},{"name":"MapReduce","slug":"BigData/Hadoop/MapReduce","link":"/categories/BigData/Hadoop/MapReduce/"}]}