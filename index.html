<!DOCTYPE html>
<html  lang="en">

<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 4.0.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>lyhcc博客</title>


    <meta property="og:type" content="website">
<meta property="og:title" content="lyhcc博客">
<meta property="og:url" content="https:&#x2F;&#x2F;lyhcc.github.io&#x2F;index.html">
<meta property="og:site_name" content="lyhcc博客">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;lyhcc.github.io&#x2F;images&#x2F;og_image.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;lyhcc.github.io&#x2F;images&#x2F;og_image.png">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">
</head>

<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="lyhcc博客" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item is-active"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
        
            <section class="section">
                <div class="container">
                    <div class="columns">
                        <div class="column is-8-tablet is-8-desktop is-7-widescreen has-order-2 column-main">
                            
    
    <div class="card">
        
                <div class="card-content article ">
                    
                        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
                            <div class="level-left">
                                <time class="level-item has-text-grey" datetime="2019-10-31T12:41:47.554Z">2019-10-31</time>
                                
                                    <div class="level-item">
                                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                                    </div>
                                    
                                        
                                            <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 549 words)
                </span>
                                            
                                                
                            </div>
                        </div>
                        
                            <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
                                
                                    <a class="has-link-black-ter" href="/post/13550.html">
                                        Hadoop通信机制和内部协议之协议
                                    </a>
                                    
                            </h1>
                            <div class="content">
                                
                                                    
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">ClientProtocol通信协议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">RefreshUserMappingProtocol</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">RefreshAuthorizationPolicyProtocol</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">ResourceManagerAdministrationProtocol</span></a></li></ol></li></ol>
    </div>
    
                                                        <h2><span id="概述">概述</span></h2><center>MapReduce核心协议</center>

<table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>ClientProtocol</td>
<td>继承于Version基类，查看作业情况监控当前集群等</td>
</tr>
<tr>
<td>RefreshUserMappingProtocol</td>
<td>刷新用户到用户组映射关系到超级用户代理组列表</td>
</tr>
<tr>
<td>RefreshAuthorizationPolicyProtocol</td>
<td>刷新HDFS和MapReduce服务几倍访问控制列表</td>
</tr>
<tr>
<td>ResourceManagerAdministrationProtocol</td>
<td>继承于GetUserMappingProtocol基类，刷新队列列表，节点列表</td>
</tr>
</tbody></table>
<h2><span id="clientprotocol通信协议">ClientProtocol通信协议</span></h2><blockquote>
<p>ClientProtocol协议是JobClient和JobTracker之间进行交流的枢纽。JobClient 可以使<br>用该协议中的函数来提交-一个作业(Job) 并执行，以了解当前系统的状态</p>
</blockquote>
<ol>
<li>提交作业<br>协议中JobClient通过Hadoop RPC的submitjob()函数提交作业(Job)，函数所包含的参数有作业ID (JobID)，然后JobClient通过getNewJoblD0函数为作业(Job) 获得一个唯一的ID。</li>
<li>操作作业<br>当用户提交作业(Job) 后，可以通过调用函数来控制该作业的执行流程，如设置提交作业的优先级(setlobPriority()函数) 、停止一个作业(killJob()函数) 、停止一个任务(illTask()函数)。</li>
<li>查看状态<br>从实现源代码来看，该通信协议还提供了一系列函数来 查看状态，如查看集群当前状态(getClusterMetrics()函数)、查看当前任务状态(getJobTrackerStatus()函数) 、获取所有任务(getllobs()函数)等。</li>
</ol>
<h2><span id="refreshusermappingprotocol">RefreshUserMappingProtocol</span></h2><blockquote>
<p>RefreshU serMappingsProtocol 协议用于更新 HDFS 和 MapReduce 级别的用户到用户组<br>映射关系及超级用户代理组列表</p>
</blockquote>
<blockquote>
<p>refreshUserToGroupsMappings() 函数和refreshSuperUserGroupsConfiguration()函数来实现，这两个函数均是通过调用Hadoop RPC来完成具体的逻辑。</p>
</blockquote>
<h2><span id="refreshauthorizationpolicyprotocol">RefreshAuthorizationPolicyProtocol</span></h2><blockquote>
<p>RefreshAuthorizationPol icyProtocol 协议用于刷新当前使用的授权策略</p>
</blockquote>
<blockquote>
<p>通过调用 Hadoop RPC 远程调用 refreshServiceAcl（）函数，实现基于 HDFS 和<br>MapReduce 级别的授权策略</p>
</blockquote>
<h3><span id="resourcemanageradministrationprotocol">ResourceManagerAdministrationProtocol</span></h3><blockquote>
<p>ResourceManagerAdministrationProtocol 协议用于更新队列列表、节点 列表 、节点资源等</p>
</blockquote>
<blockquote>
<p>该协议继承于 GetUserMappingsProtocol 基类 ，通过 Hadoop RPC 远程调用来实现节点<br>更新、资源更新 、添加标签等操作  </p>
</blockquote>
<p><strong>说明：在IDE中导入hadoop源码加载进去后，按Ctrl+鼠标左键进入即可查看源码</strong></p>

                                                            
                                                                <!-- <h2><span id="概述">概述</span></h2><center>MapReduce核心协议</center>

<table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>ClientProtocol</td>
<td>继承于Version基类，查看作业情况监控当前集群等</td>
</tr>
<tr>
<td>RefreshUserMappingProtocol</td>
<td>刷新用户到用户组映射关系到超级用户代理组列表</td>
</tr>
<tr>
<td>RefreshAuthorizationPolicyProtocol</td>
<td>刷新HDFS和MapReduce服务几倍访问控制列表</td>
</tr>
<tr>
<td>ResourceManagerAdministrationProtocol</td>
<td>继承于GetUserMappingProtocol基类，刷新队列列表，节点列表</td>
</tr>
</tbody></table>
<h2><span id="clientprotocol通信协议">ClientProtocol通信协议</span></h2><blockquote>
<p>ClientProtocol协议是JobClient和JobTracker之间进行交流的枢纽。JobClient 可以使<br>用该协议中的函数来提交-一个作业(Job) 并执行，以了解当前系统的状态</p>
</blockquote>
<ol>
<li>提交作业<br>协议中JobClient通过Hadoop RPC的submitjob()函数提交作业(Job)，函数所包含的参数有作业ID (JobID)，然后JobClient通过getNewJoblD0函数为作业(Job) 获得一个唯一的ID。</li>
<li>操作作业<br>当用户提交作业(Job) 后，可以通过调用函数来控制该作业的执行流程，如设置提交作业的优先级(setlobPriority()函数) 、停止一个作业(killJob()函数) 、停止一个任务(illTask()函数)。</li>
<li>查看状态<br>从实现源代码来看，该通信协议还提供了一系列函数来 查看状态，如查看集群当前状态(getClusterMetrics()函数)、查看当前任务状态(getJobTrackerStatus()函数) 、获取所有任务(getllobs()函数)等。</li>
</ol>
<h2><span id="refreshusermappingprotocol">RefreshUserMappingProtocol</span></h2><blockquote>
<p>RefreshU serMappingsProtocol 协议用于更新 HDFS 和 MapReduce 级别的用户到用户组<br>映射关系及超级用户代理组列表</p>
</blockquote>
<blockquote>
<p>refreshUserToGroupsMappings() 函数和refreshSuperUserGroupsConfiguration()函数来实现，这两个函数均是通过调用Hadoop RPC来完成具体的逻辑。</p>
</blockquote>
<h2><span id="refreshauthorizationpolicyprotocol">RefreshAuthorizationPolicyProtocol</span></h2><blockquote>
<p>RefreshAuthorizationPol icyProtocol 协议用于刷新当前使用的授权策略</p>
</blockquote>
<blockquote>
<p>通过调用 Hadoop RPC 远程调用 refreshServiceAcl（）函数，实现基于 HDFS 和<br>MapReduce 级别的授权策略</p>
</blockquote>
<h3><span id="resourcemanageradministrationprotocol">ResourceManagerAdministrationProtocol</span></h3><blockquote>
<p>ResourceManagerAdministrationProtocol 协议用于更新队列列表、节点 列表 、节点资源等</p>
</blockquote>
<blockquote>
<p>该协议继承于 GetUserMappingsProtocol 基类 ，通过 Hadoop RPC 远程调用来实现节点<br>更新、资源更新 、添加标签等操作  </p>
</blockquote>
<p><strong>说明：在IDE中导入hadoop源码加载进去后，按Ctrl+鼠标左键进入即可查看源码</strong></p>
 -->
                            </div>
                            
                                    
                                            
                </div>
    </div>

    
        

                

                        

    
    <div class="card">
        
                <div class="card-content article ">
                    
                        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
                            <div class="level-left">
                                <time class="level-item has-text-grey" datetime="2019-10-30T09:39:49.048Z">2019-10-30</time>
                                
                                    <div class="level-item">
                                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                                    </div>
                                    
                                        
                                            <span class="level-item has-text-grey">
                    
                    
                    9 minutes read (About 1338 words)
                </span>
                                            
                                                
                            </div>
                        </div>
                        
                            <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
                                
                                    <a class="has-link-black-ter" href="/post/56192.html">
                                        Hadoop通信机制和内部协议之RPC
                                    </a>
                                    
                            </h1>
                            <div class="content">
                                
                                                    
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">Hadoop RPC</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">RPC模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">RPC特性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">RPC例子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#null"><span class="toc-text">先定义一些常量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#null"><span class="toc-text">定义一个Service接口，协议类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#null"><span class="toc-text">Service接口的实现类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#null"><span class="toc-text">Server和Client类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#null"><span class="toc-text">客户端运行结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">其他开源RPC架构</span></a></li></ol></li></ol>
    </div>
    
                                                        <h2><span id="hadoop-rpc">Hadoop RPC</span></h2><h3><span id="rpc模型">RPC模型</span></h3><p><img src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191031181948.png" alt></p>
<ul>
<li><strong>通行模块：</strong> 请求-响应</li>
<li><strong>Stub程序：</strong> 用于保证RPC的透明性。在客户端，不在本地调用，而是将请求信息通过网络模块发送给法服务器端，服务器接收后进行解码。服务器中，Stub程序依次进行 解码（请求的参数）、调用相应的服务过程、编码返回结果等处理</li>
<li><strong>调度程序：</strong> 调度来自通行模块的请求信息，根据其中标识选一个Stub程序运行</li>
<li><strong>客户程序：</strong> 请求发出者</li>
<li><strong>服务过程：</strong> 请求接收者</li>
</ul>
<p>一个RPC的旅游：  </p>
<ol>
<li>客户端以本地调用方式产生本地Stub程序</li>
<li>该Stub程序将函数调用信息按照网络通信模块的要求封装成消息包，并交给通信模块发送到远程服务器端。</li>
<li>远程服务器端接收此消息后，将此消息发送给相应的Stub程序</li>
<li>Stub程序拆封消息，形成被调过程要求的形式，并调用对应函数</li>
<li>服务端执行被调用函数，并将结果返回给Stub程序</li>
<li>Stub程序将此结果封装成消息，通过网络通信模块逐级地传送给客户程序。</li>
</ol>
<h3><span id="rpc特性">RPC特性</span></h3><ul>
<li>透明性 调用过程就像本地调用，察觉不到它的经历</li>
<li>高性能 ：Hadoop各个系统（如HDFS、MapReduce、YARN等）均采用了Master/Slave结构，其中，Master实际上是一个RPC server，它负责响应集群中所有Slave发送的服务请求。RPC Server性能要求高，为的是能够让多个客户端并发方位</li>
<li>易用性/可控性 Hadoop系统不采用Java内嵌的RPC（RMI,Remote Method Invocation）框架的主要原因是RPC是Hadoop底层核心模块之一，需要满足易用性、高性能、轻量级等特性</li>
</ul>
<h3><span id="rpc例子">RPC例子</span></h3><p>执行过程：</p>
<ol>
<li>CalculateClient对象本地调用产生Stub程序</li>
<li>经通信模块上传至服务器CalculateServer对象，在创建Server时设置了协议和业务逻辑（服务过程），处理过后根据上述RPC过程返回</li>
<li>客户端接收后打印到日志中</li>
</ol>
<h4><span id="先定义一些常量">先定义一些常量</span></h4><blockquote>
<p>这里不需要太多的在意，直接使用在代码里面也行，在大的项目中为了使程序易于修改而这样设置  </p>
</blockquote>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 静态变量声明类</span><br><span class="line"> */</span><br><span class="line">public interface Constants &#123;</span><br><span class="line">    public interface VersionID &#123;</span><br><span class="line">        public static final long RPC_VERSION = 7788L;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static final String RPC_HOST = &quot;127.0.0.1&quot;;</span><br><span class="line">    public static final int RPC_PORT = 8888;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="定义一个service接口协议类">定义一个Service接口，协议类</span></h4><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.ipc.ProtocolInfo;</span><br><span class="line"></span><br><span class="line">@ProtocolInfo(protocolName = &quot;&quot;, protocolVersion = Constants.VersionID.RPC_VERSION)</span><br><span class="line">public interface CalculateService &#123;</span><br><span class="line"></span><br><span class="line">    //真实业务逻辑，加减法，</span><br><span class="line">    public IntWritable add(IntWritable a, IntWritable b);</span><br><span class="line">    public IntWritable sub(IntWritable a, IntWritable b);</span><br><span class="line">    public Text echo(Text mt);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>@ProtocolInfo(protocolName = “”, protocolVersion = Constants.VersionID.RPC_VERSION)</strong> 没有这句就不能将该类设置为协议，不过也可以通过继承VersionProtocol接口</p>
<h4><span id="service接口的实现类">Service接口的实现类</span></h4><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">public class CalculateServiceImpl implements CalculateService &#123;</span><br><span class="line">    /**</span><br><span class="line">    * 该方法没有也行</span><br><span class="line">    *</span><br><span class="line">    */</span><br><span class="line">    public ProtocolSignature getProtocolSignature(String arg0, long arg1, int arg2) throws IOException&#123;</span><br><span class="line">        return this.getProtocolSignature(arg0, arg1, arg2);</span><br><span class="line">    &#125;</span><br><span class="line">    /**</span><br><span class="line">     * 校验hadoop RFC版本号</span><br><span class="line">     * @param arg0</span><br><span class="line">     * @param arg1</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public long getProtocolVersion(String arg0, long arg1) throws IOException &#123;</span><br><span class="line">        return Constants.VersionID.RPC_VERSION;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public IntWritable add(IntWritable a, IntWritable b) &#123;</span><br><span class="line">        return new IntWritable(a.get() + b.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public IntWritable sub(IntWritable a, IntWritable b) &#123;</span><br><span class="line">        return new IntWritable(a.get() - b.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Text echo(Text mt) &#123;</span><br><span class="line">        return mt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="server和client类">Server和Client类</span></h4><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.ipc.RPC;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">public class CalculateServer &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger LOG = LoggerFactory.getLogger(CalculateServer.class);</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            //构造Server,并设置协议接口，主机、端口，真实业务逻辑</span><br><span class="line">            RPC.Server server = new RPC.Builder(new Configuration())</span><br><span class="line">                    .setProtocol(CalculateService.class)</span><br><span class="line">                    .setBindAddress(Constants.RPC_HOST)</span><br><span class="line">                    .setPort(Constants.RPC_PORT)</span><br><span class="line">                    .setInstance(new CalculateServiceImpl())</span><br><span class="line">                    .build();</span><br><span class="line"></span><br><span class="line">            //启动Server</span><br><span class="line">            server.start();</span><br><span class="line">            LOG.info(&quot;Server has Started!&quot;);</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            LOG.error(&quot;Server has Error&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.ipc.RPC;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.net.InetSocketAddress;</span><br><span class="line"></span><br><span class="line">public class CalculateClient &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private static final Logger LOG = LoggerFactory.getLogger(CalculateServer.class);</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        //格式化IP和端口</span><br><span class="line">        InetSocketAddress addr = new InetSocketAddress(Constants.RPC_HOST, Constants.RPC_PORT);</span><br><span class="line"></span><br><span class="line">        //校验Hadoop RPC版本号</span><br><span class="line">        long protocolVersion = RPC.getProtocolVersion(CalculateService.class);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            //获取Server连接</span><br><span class="line">            CalculateService proxy = RPC.getProxy(CalculateService.class, protocolVersion, addr, new Configuration());</span><br><span class="line"></span><br><span class="line">            IntWritable add = proxy.add(new IntWritable(1), new IntWritable(2));</span><br><span class="line">            IntWritable sub = proxy.add(new IntWritable(3), new IntWritable(2));</span><br><span class="line"></span><br><span class="line">            LOG.info(&quot;1+2 = &quot; + add);</span><br><span class="line">            LOG.info(&quot;3-2 = &quot; + sub);</span><br><span class="line"></span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            LOG.error(&quot;Client has error!&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong> 查看本程序运行结果需要一个日志文件，如果不想加，把LOG的相关语句换为打印输出就行<br>在resource文件夹下创建  log4j.properties</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, stdout  </span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender  </span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n  </span><br><span class="line">log4j.appender.logfile=org.apache.log4j.FileAppender  </span><br><span class="line">log4j.appender.logfile.File=target/spring.log  </span><br><span class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</span><br></pre></td></tr></table></figure>

<h4><span id="客户端运行结果">客户端运行结果</span></h4><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2019-10-31 18:59:28,499 WARN [org.apache.hadoop.util.Shell] - Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems</span><br><span class="line">  2019-10-31 18:59:28,619 WARN [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">  2019-10-31 18:59:29,734 INFO [hadooprfc.calculate.CalculateServer] - 1+2 = 3</span><br><span class="line">  2019-10-31 18:59:29,734 INFO [hadooprfc.calculate.CalculateServer] - 3-2 = 5</span><br></pre></td></tr></table></figure>

<h3><span id="其他开源rpc架构">其他开源RPC架构</span></h3><ul>
<li>Java RMI</li>
<li>Apache Thrift</li>
<li>Google Protocol Buffer</li>
</ul>

                                                            
                                                                <!-- <h2><span id="hadoop-rpc">Hadoop RPC</span></h2><h3><span id="rpc模型">RPC模型</span></h3><p><img src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191031181948.png" alt></p>
<ul>
<li><strong>通行模块：</strong> 请求-响应</li>
<li><strong>Stub程序：</strong> 用于保证RPC的透明性。在客户端，不在本地调用，而是将请求信息通过网络模块发送给法服务器端，服务器接收后进行解码。服务器中，Stub程序依次进行 解码（请求的参数）、调用相应的服务过程、编码返回结果等处理</li>
<li><strong>调度程序：</strong> 调度来自通行模块的请求信息，根据其中标识选一个Stub程序运行</li>
<li><strong>客户程序：</strong> 请求发出者</li>
<li><strong>服务过程：</strong> 请求接收者</li>
</ul>
<p>一个RPC的旅游：  </p>
<ol>
<li>客户端以本地调用方式产生本地Stub程序</li>
<li>该Stub程序将函数调用信息按照网络通信模块的要求封装成消息包，并交给通信模块发送到远程服务器端。</li>
<li>远程服务器端接收此消息后，将此消息发送给相应的Stub程序</li>
<li>Stub程序拆封消息，形成被调过程要求的形式，并调用对应函数</li>
<li>服务端执行被调用函数，并将结果返回给Stub程序</li>
<li>Stub程序将此结果封装成消息，通过网络通信模块逐级地传送给客户程序。</li>
</ol>
<h3><span id="rpc特性">RPC特性</span></h3><ul>
<li>透明性 调用过程就像本地调用，察觉不到它的经历</li>
<li>高性能 ：Hadoop各个系统（如HDFS、MapReduce、YARN等）均采用了Master/Slave结构，其中，Master实际上是一个RPC server，它负责响应集群中所有Slave发送的服务请求。RPC Server性能要求高，为的是能够让多个客户端并发方位</li>
<li>易用性/可控性 Hadoop系统不采用Java内嵌的RPC（RMI,Remote Method Invocation）框架的主要原因是RPC是Hadoop底层核心模块之一，需要满足易用性、高性能、轻量级等特性</li>
</ul>
<h3><span id="rpc例子">RPC例子</span></h3><p>执行过程：</p>
<ol>
<li>CalculateClient对象本地调用产生Stub程序</li>
<li>经通信模块上传至服务器CalculateServer对象，在创建Server时设置了协议和业务逻辑（服务过程），处理过后根据上述RPC过程返回</li>
<li>客户端接收后打印到日志中</li>
</ol>
<h4><span id="先定义一些常量">先定义一些常量</span></h4><blockquote>
<p>这里不需要太多的在意，直接使用在代码里面也行，在大的项目中为了使程序易于修改而这样设置  </p>
</blockquote>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 静态变量声明类</span><br><span class="line"> */</span><br><span class="line">public interface Constants &#123;</span><br><span class="line">    public interface VersionID &#123;</span><br><span class="line">        public static final long RPC_VERSION = 7788L;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static final String RPC_HOST = &quot;127.0.0.1&quot;;</span><br><span class="line">    public static final int RPC_PORT = 8888;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="定义一个service接口协议类">定义一个Service接口，协议类</span></h4><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.ipc.ProtocolInfo;</span><br><span class="line"></span><br><span class="line">@ProtocolInfo(protocolName = &quot;&quot;, protocolVersion = Constants.VersionID.RPC_VERSION)</span><br><span class="line">public interface CalculateService &#123;</span><br><span class="line"></span><br><span class="line">    //真实业务逻辑，加减法，</span><br><span class="line">    public IntWritable add(IntWritable a, IntWritable b);</span><br><span class="line">    public IntWritable sub(IntWritable a, IntWritable b);</span><br><span class="line">    public Text echo(Text mt);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>@ProtocolInfo(protocolName = “”, protocolVersion = Constants.VersionID.RPC_VERSION)</strong> 没有这句就不能将该类设置为协议，不过也可以通过继承VersionProtocol接口</p>
<h4><span id="service接口的实现类">Service接口的实现类</span></h4><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">public class CalculateServiceImpl implements CalculateService &#123;</span><br><span class="line">    /**</span><br><span class="line">    * 该方法没有也行</span><br><span class="line">    *</span><br><span class="line">    */</span><br><span class="line">    public ProtocolSignature getProtocolSignature(String arg0, long arg1, int arg2) throws IOException&#123;</span><br><span class="line">        return this.getProtocolSignature(arg0, arg1, arg2);</span><br><span class="line">    &#125;</span><br><span class="line">    /**</span><br><span class="line">     * 校验hadoop RFC版本号</span><br><span class="line">     * @param arg0</span><br><span class="line">     * @param arg1</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public long getProtocolVersion(String arg0, long arg1) throws IOException &#123;</span><br><span class="line">        return Constants.VersionID.RPC_VERSION;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public IntWritable add(IntWritable a, IntWritable b) &#123;</span><br><span class="line">        return new IntWritable(a.get() + b.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public IntWritable sub(IntWritable a, IntWritable b) &#123;</span><br><span class="line">        return new IntWritable(a.get() - b.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Text echo(Text mt) &#123;</span><br><span class="line">        return mt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="server和client类">Server和Client类</span></h4><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.ipc.RPC;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">public class CalculateServer &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger LOG = LoggerFactory.getLogger(CalculateServer.class);</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            //构造Server,并设置协议接口，主机、端口，真实业务逻辑</span><br><span class="line">            RPC.Server server = new RPC.Builder(new Configuration())</span><br><span class="line">                    .setProtocol(CalculateService.class)</span><br><span class="line">                    .setBindAddress(Constants.RPC_HOST)</span><br><span class="line">                    .setPort(Constants.RPC_PORT)</span><br><span class="line">                    .setInstance(new CalculateServiceImpl())</span><br><span class="line">                    .build();</span><br><span class="line"></span><br><span class="line">            //启动Server</span><br><span class="line">            server.start();</span><br><span class="line">            LOG.info(&quot;Server has Started!&quot;);</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            LOG.error(&quot;Server has Error&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.ipc.RPC;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.net.InetSocketAddress;</span><br><span class="line"></span><br><span class="line">public class CalculateClient &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private static final Logger LOG = LoggerFactory.getLogger(CalculateServer.class);</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        //格式化IP和端口</span><br><span class="line">        InetSocketAddress addr = new InetSocketAddress(Constants.RPC_HOST, Constants.RPC_PORT);</span><br><span class="line"></span><br><span class="line">        //校验Hadoop RPC版本号</span><br><span class="line">        long protocolVersion = RPC.getProtocolVersion(CalculateService.class);</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            //获取Server连接</span><br><span class="line">            CalculateService proxy = RPC.getProxy(CalculateService.class, protocolVersion, addr, new Configuration());</span><br><span class="line"></span><br><span class="line">            IntWritable add = proxy.add(new IntWritable(1), new IntWritable(2));</span><br><span class="line">            IntWritable sub = proxy.add(new IntWritable(3), new IntWritable(2));</span><br><span class="line"></span><br><span class="line">            LOG.info(&quot;1+2 = &quot; + add);</span><br><span class="line">            LOG.info(&quot;3-2 = &quot; + sub);</span><br><span class="line"></span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            LOG.error(&quot;Client has error!&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong> 查看本程序运行结果需要一个日志文件，如果不想加，把LOG的相关语句换为打印输出就行<br>在resource文件夹下创建  log4j.properties</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, stdout  </span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender  </span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n  </span><br><span class="line">log4j.appender.logfile=org.apache.log4j.FileAppender  </span><br><span class="line">log4j.appender.logfile.File=target/spring.log  </span><br><span class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</span><br></pre></td></tr></table></figure>

<h4><span id="客户端运行结果">客户端运行结果</span></h4><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2019-10-31 18:59:28,499 WARN [org.apache.hadoop.util.Shell] - Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems</span><br><span class="line">  2019-10-31 18:59:28,619 WARN [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">  2019-10-31 18:59:29,734 INFO [hadooprfc.calculate.CalculateServer] - 1+2 = 3</span><br><span class="line">  2019-10-31 18:59:29,734 INFO [hadooprfc.calculate.CalculateServer] - 3-2 = 5</span><br></pre></td></tr></table></figure>

<h3><span id="其他开源rpc架构">其他开源RPC架构</span></h3><ul>
<li>Java RMI</li>
<li>Apache Thrift</li>
<li>Google Protocol Buffer</li>
</ul>
 -->
                            </div>
                            
                                    
                                            
                </div>
    </div>

    
        

                

                        

    
    <div class="card">
        
                <div class="card-content article ">
                    
                        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
                            <div class="level-left">
                                <time class="level-item has-text-grey" datetime="2019-10-28T10:01:26.105Z">2019-10-28</time>
                                
                                    <div class="level-item">
                                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                                    </div>
                                    
                                        
                                            <span class="level-item has-text-grey">
                    
                    
                    3 minutes read (About 397 words)
                </span>
                                            
                                                
                            </div>
                        </div>
                        
                            <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
                                
                                    <a class="has-link-black-ter" href="/post/20979.html">
                                        hadoop序列化
                                    </a>
                                    
                            </h1>
                            <div class="content">
                                
                                                    
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">序列化介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">Java序列化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">Hadoop 不使用Java序列化原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">Hadoop 序列化</span></a></li></ol>
    </div>
    
                                                        <h3><span id="序列化介绍">序列化介绍</span></h3><blockquote>
<p>序列化是一种将对象的状态信息转化成可以存储或者传输的过程<br>不是某一种编程语言所独有的特性</p>
</blockquote>
<h3><span id="java序列化">Java序列化</span></h3><blockquote>
<p>Java通过实现Serializable接口</p>
</blockquote>
<figure class="highlight java hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> java. io.Serializable ;</span><br><span class="line"></span><br><span class="line">／＊＊定义一个可以序列化的 App 信息类. */</span><br><span class="line"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Appinfo</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Serializable</span></span>&#123;</span><br><span class="line">	／／序列化标识</span><br><span class="line">	<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">long</span> serialVersionUID = <span class="hljs-number">11</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3><span id="hadoop-不使用java序列化原因">Hadoop 不使用Java序列化原因</span></h3><blockquote>
<ol>
<li>Java 自带的序列化机制占用内存空间大，额外的开销会导致速度降低，Hadoop对序列化的要求较高，需要保证序列化速度快、体积小、占用带宽低等特性</li>
<li>Hadoop 序列化机制是将对象序列化到流中，而 Java 序列化机制是不断创建新对象</li>
</ol>
</blockquote>
<h3><span id="hadoop-序列化">Hadoop 序列化</span></h3><blockquote>
<p>在 Hadoop 序列化机制中，org.apache.hadoop.io包中定义了大量的可序列化对象<br>均实现Wriable接口的两个函数，<br> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(1) write：将对象写入字节流：</span><br><span class="line">(2) readFields：从字节流中解析出对象。</span><br></pre></td></tr></table></figure></p>
</blockquote>
<ul>
<li>优势<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 减少垃圾回收：从流中反序列化数据到当前对象，重复使用当前对象，减少了垃圾回收GC ;</span><br><span class="line">2. 减少网络流量 ： 序列化和反序列化对象类型不变 ，因此可以只保存必要的数据来减少网络流量；</span><br><span class="line">3. 提升 I/O 效率 ： 由于序列化和反序列化的数据量减少了，配合Hadoop压缩机制，可以提升I/O效率。</span><br></pre></td></tr></table></figure></li>
</ul>

                                                            
                                                                <!-- <h3><span id="序列化介绍">序列化介绍</span></h3><blockquote>
<p>序列化是一种将对象的状态信息转化成可以存储或者传输的过程<br>不是某一种编程语言所独有的特性</p>
</blockquote>
<h3><span id="java序列化">Java序列化</span></h3><blockquote>
<p>Java通过实现Serializable接口</p>
</blockquote>
<figure class="highlight java hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> java. io.Serializable ;</span><br><span class="line"></span><br><span class="line">／＊＊定义一个可以序列化的 App 信息类. */</span><br><span class="line"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Appinfo</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Serializable</span></span>&#123;</span><br><span class="line">	／／序列化标识</span><br><span class="line">	<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">long</span> serialVersionUID = <span class="hljs-number">11</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3><span id="hadoop-不使用java序列化原因">Hadoop 不使用Java序列化原因</span></h3><blockquote>
<ol>
<li>Java 自带的序列化机制占用内存空间大，额外的开销会导致速度降低，Hadoop对序列化的要求较高，需要保证序列化速度快、体积小、占用带宽低等特性</li>
<li>Hadoop 序列化机制是将对象序列化到流中，而 Java 序列化机制是不断创建新对象</li>
</ol>
</blockquote>
<h3><span id="hadoop-序列化">Hadoop 序列化</span></h3><blockquote>
<p>在 Hadoop 序列化机制中，org.apache.hadoop.io包中定义了大量的可序列化对象<br>均实现Wriable接口的两个函数，<br> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(1) write：将对象写入字节流：</span><br><span class="line">(2) readFields：从字节流中解析出对象。</span><br></pre></td></tr></table></figure></p>
</blockquote>
<ul>
<li>优势<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 减少垃圾回收：从流中反序列化数据到当前对象，重复使用当前对象，减少了垃圾回收GC ;</span><br><span class="line">2. 减少网络流量 ： 序列化和反序列化对象类型不变 ，因此可以只保存必要的数据来减少网络流量；</span><br><span class="line">3. 提升 I/O 效率 ： 由于序列化和反序列化的数据量减少了，配合Hadoop压缩机制，可以提升I/O效率。</span><br></pre></td></tr></table></figure></li>
</ul>
 -->
                            </div>
                            
                                    
                                            
                </div>
    </div>

    
        

                

                        

    
    <div class="card">
        
                <div class="card-content article ">
                    
                        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
                            <div class="level-left">
                                <time class="level-item has-text-grey" datetime="2019-10-26T10:46:05.391Z">2019-10-26</time>
                                
                                    <div class="level-item">
                                        <a class="has-link-grey -link" href="/categories/BigData/">BigData</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/BigData/Hadoop/">Hadoop</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/BigData/Hadoop/MapReduce/">MapReduce</a>
                                    </div>
                                    
                                        
                                            <span class="level-item has-text-grey">
                    
                    
                    8 minutes read (About 1134 words)
                </span>
                                            
                                                
                            </div>
                        </div>
                        
                            <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
                                
                                    <a class="has-link-black-ter" href="/post/5429.html">
                                        MapReduce介绍
                                    </a>
                                    
                            </h1>
                            <div class="content">
                                
                                                    
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">MapReduce的定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">MapReduce优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">MapReduce核心思想</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">MapReduce进程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">MapReduce编程规范</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">第一代和第二代MapReduce的区别</span></a></li></ol>
    </div>
    
                                                        <h2><span id="mapreduce的定义">MapReduce的定义</span></h2><blockquote>
<p>&emsp;&emsp;Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。<br>&emsp;&emsp;Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。</p>
</blockquote>
<h2><span id="mapreduce优缺点">MapReduce优缺点</span></h2><h3><span id="优点">优点</span></h3><ol>
<li><strong>MapReduce 易于编程</strong>。它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</li>
<li><strong>良好的扩展性</strong>。当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</li>
<li><strong>高容错性</strong>。MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由 Hadoop内部完成的。</li>
<li><strong>适合PB级以上海量数据的离线处理</strong>。这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，MapReduce很难做到。<h3><span id="缺点">缺点</span></h3><blockquote>
<p>MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。</p>
</blockquote>
</li>
</ol>
<ul>
<li><strong>实时计算</strong>。MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。</li>
<li><strong>流式计算</strong>。流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。</li>
<li><strong>DAG（有向图）计算</strong>。多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</li>
</ul>
<h2><span id="mapreduce核心思想">MapReduce核心思想</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191026201155.png" alt>  </p>
<blockquote>
<ol>
<li>分布式的运算程序往往需要分成至少2个阶段。<br>第一个阶段的maptask并发实例，完全并行运行，互不相干。</li>
<li>第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出。</li>
<li>MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行。</li>
</ol>
</blockquote>
<h2><span id="mapreduce进程">MapReduce进程</span></h2><blockquote>
<p>一个完整的mapreduce程序在分布式运行时有三类实例进程：</p>
</blockquote>
<ul>
<li>MrAppMaster：负责整个程序的过程调度及状态协调。</li>
<li>MapTask：负责map阶段的整个数据处理流程。</li>
<li>ReduceTask：负责reduce阶段的整个数据处理流程。</li>
</ul>
<h3><span id="mapreduce编程规范">MapReduce编程规范</span></h3><blockquote>
<p>用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端)  </p>
</blockquote>
<ul>
<li><p>Mapper阶段  </p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">（1）用户自定义的Mapper要继承自己的父类  </span><br><span class="line">（2）Mapper的输入数据是KV对的形式（KV的类型可自定义）  </span><br><span class="line">（3）Mapper中的业务逻辑写在map()方法中  </span><br><span class="line">（4）Mapper的输出数据是KV对的形式（KV的类型可自定义）  </span><br><span class="line">（5）map()方法（maptask进程）对每一个&lt;K,V&gt;调用一次</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191026215909.png" alt></p>
</li>
<li><p>Reduce阶段  </p>
</li>
</ul>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">（1）用户自定义的Reducer要继承自己的父类   </span><br><span class="line">（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV  </span><br><span class="line">（3）Reducer的业务逻辑写在reduce()方法中  </span><br><span class="line">（4）Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法</span><br></pre></td></tr></table></figure>

<h2><span id="第一代和第二代mapreduce的区别">第一代和第二代MapReduce的区别</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191028175301.png" alt></p>

                                                            
                                                                <!-- <h2><span id="mapreduce的定义">MapReduce的定义</span></h2><blockquote>
<p>&emsp;&emsp;Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。<br>&emsp;&emsp;Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。</p>
</blockquote>
<h2><span id="mapreduce优缺点">MapReduce优缺点</span></h2><h3><span id="优点">优点</span></h3><ol>
<li><strong>MapReduce 易于编程</strong>。它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</li>
<li><strong>良好的扩展性</strong>。当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</li>
<li><strong>高容错性</strong>。MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由 Hadoop内部完成的。</li>
<li><strong>适合PB级以上海量数据的离线处理</strong>。这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，MapReduce很难做到。<h3><span id="缺点">缺点</span></h3><blockquote>
<p>MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。</p>
</blockquote>
</li>
</ol>
<ul>
<li><strong>实时计算</strong>。MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。</li>
<li><strong>流式计算</strong>。流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。</li>
<li><strong>DAG（有向图）计算</strong>。多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</li>
</ul>
<h2><span id="mapreduce核心思想">MapReduce核心思想</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191026201155.png" alt>  </p>
<blockquote>
<ol>
<li>分布式的运算程序往往需要分成至少2个阶段。<br>第一个阶段的maptask并发实例，完全并行运行，互不相干。</li>
<li>第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出。</li>
<li>MapReduce编程模型只能包含一个map阶段和一个reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行。</li>
</ol>
</blockquote>
<h2><span id="mapreduce进程">MapReduce进程</span></h2><blockquote>
<p>一个完整的mapreduce程序在分布式运行时有三类实例进程：</p>
</blockquote>
<ul>
<li>MrAppMaster：负责整个程序的过程调度及状态协调。</li>
<li>MapTask：负责map阶段的整个数据处理流程。</li>
<li>ReduceTask：负责reduce阶段的整个数据处理流程。</li>
</ul>
<h3><span id="mapreduce编程规范">MapReduce编程规范</span></h3><blockquote>
<p>用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端)  </p>
</blockquote>
<ul>
<li><p>Mapper阶段  </p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">（1）用户自定义的Mapper要继承自己的父类  </span><br><span class="line">（2）Mapper的输入数据是KV对的形式（KV的类型可自定义）  </span><br><span class="line">（3）Mapper中的业务逻辑写在map()方法中  </span><br><span class="line">（4）Mapper的输出数据是KV对的形式（KV的类型可自定义）  </span><br><span class="line">（5）map()方法（maptask进程）对每一个&lt;K,V&gt;调用一次</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191026215909.png" alt></p>
</li>
<li><p>Reduce阶段  </p>
</li>
</ul>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">（1）用户自定义的Reducer要继承自己的父类   </span><br><span class="line">（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV  </span><br><span class="line">（3）Reducer的业务逻辑写在reduce()方法中  </span><br><span class="line">（4）Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法</span><br></pre></td></tr></table></figure>

<h2><span id="第一代和第二代mapreduce的区别">第一代和第二代MapReduce的区别</span></h2><p><img src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191028175301.png" alt></p>
 -->
                            </div>
                            
                                    
                                            
                </div>
    </div>

    
        

                

                        

    
    <div class="card">
        
                <div class="card-content article ">
                    
                        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
                            <div class="level-left">
                                <time class="level-item has-text-grey" datetime="2019-10-26T08:47:04.559Z">2019-10-26</time>
                                
                                    <div class="level-item">
                                        <a class="has-link-grey -link" href="/categories/BigData/">BigData</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/BigData/Hadoop/">Hadoop</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/BigData/Hadoop/HDFS/">HDFS</a>
                                    </div>
                                    
                                        
                                            <span class="level-item has-text-grey">
                    
                    
                    5 minutes read (About 794 words)
                </span>
                                            
                                                
                            </div>
                        </div>
                        
                            <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
                                
                                    <a class="has-link-black-ter" href="/post/21534.html">
                                        HDFS快照管理
                                    </a>
                                    
                            </h1>
                            <div class="content">
                                
                                                    
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">快照管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">快照影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">基本语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">案例实操</span></a></li></ol></li></ol>
    </div>
    
                                                        <h2><span id="快照管理">快照管理</span></h2><blockquote>
<p>快照相当于对目录做一个备份。并不会立即复制所有文件，而是指向同一个文件。当写入发生时，才会产生新文件。</p>
</blockquote>
<h3><span id="快照影响">快照影响</span></h3><ul>
<li>快照创建瞬间完成，所耗时间成本为O(1)</li>
<li>快照修改时才会使用额外的额外的内存空间，内存成本O(M),M表示修改过的文件或目录数</li>
<li>快照记录块和文件大小，不对DataNode中的块进行复制</li>
<li><em>说明：*</em> 快照可以在HDFS任何目录下设置，一个目录最多容纳65536个并发快照</li>
</ul>
<h3><span id="基本语法">基本语法</span></h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">（1）hdfs dfsadmin -allowSnapshot 路径   （功能描述：开启指定目录的快照功能）</span><br><span class="line">（2）hdfs dfsadmin -disallowSnapshot 路径 （功能描述：禁用指定目录的快照功能，默认是禁用）</span><br><span class="line">（3）hdfs dfs -createSnapshot 路径        （功能描述：对目录创建快照）</span><br><span class="line">（4）hdfs dfs -createSnapshot 路径 名称   （功能描述：指定名称创建快照）</span><br><span class="line">（5）hdfs dfs -renameSnapshot 路径 旧名称 新名称 （功能描述：重命名快照）</span><br><span class="line">（6）hdfs lsSnapshottableDir         （功能描述：列出当前用户所有已快照目录）</span><br><span class="line">（7）hdfs snapshotDiff 路径1 路径2 （功能描述：比较两个快照目录的不同之处）</span><br><span class="line">（8）hdfs dfs -deleteSnapshot &lt;path&gt; &lt;snapshotName&gt;  （功能描述：删除快照）</span><br></pre></td></tr></table></figure>
<h3><span id="案例实操">案例实操</span></h3><ol>
<li><p>开启/禁用指定目录的快照功能</p>
<blockquote>
<p>指定创建目录的位置为 /tmp/snapshot(即快照的存储目录)，在指定目录之前必须创建目录，不然会报错</p>
</blockquote>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -allowSnapshot /tmp/snapshot	</span><br><span class="line">hdfs dfsadmin -disallowSnapshot /tmp/snapshot	 //禁用时，对应的目录不允许存在快照</span><br></pre></td></tr></table></figure></li>
<li><p>对目录创建快照</p>
<blockquote>
<p>只有被开启快照功能的目录才能创建快照</p>
</blockquote>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -createSnapshot /tmp/snapshot		// 对目录创建快照</span><br><span class="line">hdfs dfs -createSnapshot /tmp/snapshot snapshot //重命名快照（注：快照是只读的，无法修改名）</span><br><span class="line">通过web访问hdfs://Master:9000/tmp/snapshot/.snapshot/s…..// 快照和源文件使用相同数据块</span><br></pre></td></tr></table></figure></li>
<li><p>查看快照</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -lsr /tmp/snapshot/.snapshot/   //查看快照目录的详细信息</span><br><span class="line">hdfs lsSnapshottableDir                  //查看所有允许快照的目录</span><br></pre></td></tr></table></figure></li>
<li><p>更改快照名字</p>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -renameSnapshot /tmp/snapshot/ snapshot snapshot1	</span><br><span class="line"></span><br><span class="line">注：路径只是你创建得名字/tmp/snapshot，不要带后边得/tmp/snapshot/.snapshot/，不然会出现</span><br><span class="line">hdfs dfs -renameSnapshot /tmp/snapshot/.snapshot/ snapshot1 snapshot</span><br><span class="line">renameSnapshot: Modification on a read-only snapshot is disallowed</span><br></pre></td></tr></table></figure>
</li>
<li><p>比较两个快照目录的不同之处</p>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vmaster opt]# hdfs snapshotDiff /tmp/snapshot s1 s2</span><br><span class="line">Difference between snapshot s1 and snapshot s2 under directory /tmp/snapshot:</span><br><span class="line">M	.</span><br><span class="line">+	./p</span><br></pre></td></tr></table></figure>
<p> <strong>符号的意义：</strong>  </p>
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>+</td>
<td>文件或者目录被创建</td>
</tr>
<tr>
<td>-</td>
<td>文件或目录被删除</td>
</tr>
<tr>
<td>M</td>
<td>文件或目录被修改</td>
</tr>
<tr>
<td>R</td>
<td>文件或目录被重命名</td>
</tr>
</tbody></table>
</li>
<li><p>恢复快照</p>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.自定义创建一个快照名：hdfs dfs -createSnapshot /HAHA1 snapshot1</span><br><span class="line">2.展示原文件包含内容：Hadoop fs -ls /HAHA1</span><br><span class="line">3.里面有五个文件、删除其中1~2个</span><br><span class="line">/HAHA1/.snapshot/snapshot1</span><br><span class="line">4.回复快照：hdfs dfs -cp /HAHA1/.snapshot/snapshot1 /snapshot</span><br></pre></td></tr></table></figure></li>
<li><p>删除快照                                             </p>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dfs dfs -deleteSnapshot 快照目录 快照名称</span><br><span class="line">dfs dfs -deleteSnapshot /tmp/snapshot snapshot1</span><br></pre></td></tr></table></figure></li>
</ol>

                                                            
                                                                <!-- <h2><span id="快照管理">快照管理</span></h2><blockquote>
<p>快照相当于对目录做一个备份。并不会立即复制所有文件，而是指向同一个文件。当写入发生时，才会产生新文件。</p>
</blockquote>
<h3><span id="快照影响">快照影响</span></h3><ul>
<li>快照创建瞬间完成，所耗时间成本为O(1)</li>
<li>快照修改时才会使用额外的额外的内存空间，内存成本O(M),M表示修改过的文件或目录数</li>
<li>快照记录块和文件大小，不对DataNode中的块进行复制</li>
<li><em>说明：*</em> 快照可以在HDFS任何目录下设置，一个目录最多容纳65536个并发快照</li>
</ul>
<h3><span id="基本语法">基本语法</span></h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">（1）hdfs dfsadmin -allowSnapshot 路径   （功能描述：开启指定目录的快照功能）</span><br><span class="line">（2）hdfs dfsadmin -disallowSnapshot 路径 （功能描述：禁用指定目录的快照功能，默认是禁用）</span><br><span class="line">（3）hdfs dfs -createSnapshot 路径        （功能描述：对目录创建快照）</span><br><span class="line">（4）hdfs dfs -createSnapshot 路径 名称   （功能描述：指定名称创建快照）</span><br><span class="line">（5）hdfs dfs -renameSnapshot 路径 旧名称 新名称 （功能描述：重命名快照）</span><br><span class="line">（6）hdfs lsSnapshottableDir         （功能描述：列出当前用户所有已快照目录）</span><br><span class="line">（7）hdfs snapshotDiff 路径1 路径2 （功能描述：比较两个快照目录的不同之处）</span><br><span class="line">（8）hdfs dfs -deleteSnapshot &lt;path&gt; &lt;snapshotName&gt;  （功能描述：删除快照）</span><br></pre></td></tr></table></figure>
<h3><span id="案例实操">案例实操</span></h3><ol>
<li><p>开启/禁用指定目录的快照功能</p>
<blockquote>
<p>指定创建目录的位置为 /tmp/snapshot(即快照的存储目录)，在指定目录之前必须创建目录，不然会报错</p>
</blockquote>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -allowSnapshot /tmp/snapshot	</span><br><span class="line">hdfs dfsadmin -disallowSnapshot /tmp/snapshot	 //禁用时，对应的目录不允许存在快照</span><br></pre></td></tr></table></figure></li>
<li><p>对目录创建快照</p>
<blockquote>
<p>只有被开启快照功能的目录才能创建快照</p>
</blockquote>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -createSnapshot /tmp/snapshot		// 对目录创建快照</span><br><span class="line">hdfs dfs -createSnapshot /tmp/snapshot snapshot //重命名快照（注：快照是只读的，无法修改名）</span><br><span class="line">通过web访问hdfs://Master:9000/tmp/snapshot/.snapshot/s…..// 快照和源文件使用相同数据块</span><br></pre></td></tr></table></figure></li>
<li><p>查看快照</p>
<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -lsr /tmp/snapshot/.snapshot/   //查看快照目录的详细信息</span><br><span class="line">hdfs lsSnapshottableDir                  //查看所有允许快照的目录</span><br></pre></td></tr></table></figure></li>
<li><p>更改快照名字</p>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -renameSnapshot /tmp/snapshot/ snapshot snapshot1	</span><br><span class="line"></span><br><span class="line">注：路径只是你创建得名字/tmp/snapshot，不要带后边得/tmp/snapshot/.snapshot/，不然会出现</span><br><span class="line">hdfs dfs -renameSnapshot /tmp/snapshot/.snapshot/ snapshot1 snapshot</span><br><span class="line">renameSnapshot: Modification on a read-only snapshot is disallowed</span><br></pre></td></tr></table></figure>
</li>
<li><p>比较两个快照目录的不同之处</p>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vmaster opt]# hdfs snapshotDiff /tmp/snapshot s1 s2</span><br><span class="line">Difference between snapshot s1 and snapshot s2 under directory /tmp/snapshot:</span><br><span class="line">M	.</span><br><span class="line">+	./p</span><br></pre></td></tr></table></figure>
<p> <strong>符号的意义：</strong>  </p>
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>+</td>
<td>文件或者目录被创建</td>
</tr>
<tr>
<td>-</td>
<td>文件或目录被删除</td>
</tr>
<tr>
<td>M</td>
<td>文件或目录被修改</td>
</tr>
<tr>
<td>R</td>
<td>文件或目录被重命名</td>
</tr>
</tbody></table>
</li>
<li><p>恢复快照</p>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.自定义创建一个快照名：hdfs dfs -createSnapshot /HAHA1 snapshot1</span><br><span class="line">2.展示原文件包含内容：Hadoop fs -ls /HAHA1</span><br><span class="line">3.里面有五个文件、删除其中1~2个</span><br><span class="line">/HAHA1/.snapshot/snapshot1</span><br><span class="line">4.回复快照：hdfs dfs -cp /HAHA1/.snapshot/snapshot1 /snapshot</span><br></pre></td></tr></table></figure></li>
<li><p>删除快照                                             </p>
 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dfs dfs -deleteSnapshot 快照目录 快照名称</span><br><span class="line">dfs dfs -deleteSnapshot /tmp/snapshot snapshot1</span><br></pre></td></tr></table></figure></li>
</ol>
 -->
                            </div>
                            
                                    
                                            
                </div>
    </div>

    
        

                

                        

    
    <div class="card">
        
                <div class="card-content article ">
                    
                        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
                            <div class="level-left">
                                <time class="level-item has-text-grey" datetime="2019-10-26T08:35:02.893Z">2019-10-26</time>
                                
                                    <div class="level-item">
                                        <a class="has-link-grey -link" href="/categories/BigData/">BigData</a>
                                    </div>
                                    
                                        
                                            <span class="level-item has-text-grey">
                    
                    
                    18 minutes read (About 2695 words)
                </span>
                                            
                                                
                            </div>
                        </div>
                        
                            <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
                                
                                    <a class="has-link-black-ter" href="/post/2260.html">
                                        大数据介绍
                                    </a>
                                    
                            </h1>
                            <div class="content">
                                
                                                    
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">什么是大数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">数据单位</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">大数据的特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">大数据相关技术</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">大数据带来的变革</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">大数据小故事</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#null"><span class="toc-text">其他故事</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">大数据初步学习路线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">起源 Google 在大数据方面的三大论文 （谷歌三宝）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">Hadoop 三大发行版本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">硬件要求</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#null"><span class="toc-text">内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#null"><span class="toc-text">硬盘:500G+</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-text">科普</span></a></li></ol>
    </div>
    
                                                        <h2><span id="什么是大数据">什么是大数据</span></h2><blockquote>
<p>百度百科的定义,大数据（BIG DATA），指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产</p>
</blockquote>
<blockquote>
<p>在目前的业界尚未对大数据由清晰明确的定义, 它的第一次出现是在麦肯锡公司的报告中出现的, 在维基百科上的较为模糊的定义是很难运用软件的手段获取大量的内容信息, 对其处理后整理得出的数据集合。其他计算机学科的学者给出的定义是数据的尺度极为巨大, 常规的数据处理软件无法对数据识别、存储和应用的海量数据信息</p>
</blockquote>
<blockquote>
<p>维基百科的定义，大数据是指无法在可承受的时间范围内用常规软件工具进行捕捉、管理和处理的数据集合。</p>
</blockquote>
<blockquote>
<p>研究机构Gartner定义，“大数据”是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p>
</blockquote>
<h2><span id="数据单位">数据单位</span></h2><p>1MB = 1024KB、1GB = 1024MB<br>1TB = 1024GB、1PB = 1024TB</p>
<h2><span id="大数据的特征">大数据的特征</span></h2><ul>
<li>容量（Volume）：数据的大小决定所考虑的数据的价值和潜在的信息；</li>
<li>种类（Variety）：数据类型的多样性；</li>
<li>速度（Velocity）：指获得数据的速度；</li>
<li>可变性（Variability）：妨碍了处理和有效地管理数据的过程。</li>
<li>真实性（Veracity）：数据的质量</li>
<li>复杂性（Complexity）：数据量巨大，来源多渠道</li>
<li>价值（value）：合理运用大数据，以低成本创造高价值</li>
</ul>
<h2><span id="大数据相关技术">大数据相关技术</span></h2><ol>
<li><strong>数据采集：</strong> OLAP(联机分析处理)和数据挖掘的基础。ETL工具负责将分布的、异构的数据源进行抽取，抽取到中间层，进行清洗、转换、集成，（不过对于负责的逻辑处理不会这么干，用Spark或者其他的进行处理），最后放到数据仓库中存储，如Hive</li>
<li><strong>数据存取：</strong> 关系型数据库、NoSQL(Not Only SQL,泛指非关系型数据库)，SQL等</li>
<li><strong>基础架构：</strong> 云存储、分布式文件存储等</li>
<li><strong>数据处理：</strong> 自然语言处理(Natural Language Processing, NLP)</li>
<li><strong>数据分析：</strong> 假设检验、显著性检验、差异检验、差异分析、相关性分析、T检验、方差分析、卡方分析、偏相关性分析、距离分析、回归分析、简单回归分析、多元回归分析、逐步回归、预测和残差分析、岭回归、Logistic回归分析、曲线估计、因子分析、聚类分析、主成分分析、判别分析、对应分析、快速聚类和聚类法、对应分析、多元对应分析等</li>
<li><strong>数据挖掘：</strong> 分类（Classification）、估计（Estimation）、预测（Prediction)、相关性分析或关联规则（Association）、复杂数据类型挖掘（Text、Web、图形图像、视频、音频等）</li>
<li><strong>模型预测：</strong> 预测模型、机器学习、建模仿真</li>
<li><strong>结果呈现：</strong> 云计算、标签云、关系图等</li>
</ol>
<h2><span id="大数据带来的变革">大数据带来的变革</span></h2><h3><span id="大数据小故事">大数据小故事</span></h3><blockquote>
<p>&emsp;&emsp;最早关于大数据的故事发生在美国第二大的超市塔吉特百货（Target）。孕妇对于零售商来说是个含金量很高的顾客群体。但是他们一般会去专门的孕妇商店而不是在Target购买孕期用品。人们一提起Target，往往想到的都是清洁用品、袜子和手纸之类的日常生活用品，却忽视了Target有孕妇需要的一切。那么Target有什么办法可以把这部分细分顾客从孕妇产品专卖店的手里截留下来呢？</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;为此，Target的市场营销人员求助于Target的顾客数据分析部的高级经理Andrew Pole，要求他建立一个模型，在孕妇第2个妊娠期就把她们给确认出来。在美国出生记录是公开的，等孩子出生了，新生儿母亲就会被铺天盖地的产品优惠广告包围，那时候Target再行动就晚了，因此必须赶在孕妇第2个妊娠期行动起来。如果Target能够赶在所有零售商之前知道哪位顾客怀孕了，市场营销部门就可以早早的给他们发出量身定制的孕妇优惠广告，早早圈定宝贵的顾客资源。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;可是怀孕是很私密的信息，如何能够准确地判断哪位顾客怀孕了呢？Andrew Pole想到了Target有一个迎婴聚会（baby shower）的登记表。Andrew Pole开始对这些登记表里的顾客的消费数据进行建模分析，不久就发现了许多非常有用的数据模式。比如模型发现，许多孕妇在第2个妊娠期的开始会买许多大包装的无香味护手霜；在怀孕的最初20周大量购买补充钙、镁、锌的善存片之类的保健品。最后Andrew Pole选出了25种典型商品的消费数据构建了“怀孕预测指数”，通过这个指数，Target能够在很小的误差范围内预测到顾客的怀孕情况，因此Target就能早早地把孕妇优惠广告寄发给顾客。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;那么，顾客收到这样的广告会不会吓坏了呢？Target很聪明地避免了这种情况，它把孕妇用品的优惠广告夹杂在其他一大堆与怀孕不相关的商品优惠广告当中，这样顾客就不知道Target知道她怀孕了。百密一疏的是，Target的这种优惠广告间接地令一个蒙在鼓里的父亲意外发现他高中生的女儿怀孕了，此事甚至被《纽约时报》报道了，结果Target大数据的巨大威力轰动了全美。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;根据Andrew Pole的大数据模型,Target制订了全新的广告营销方案，结果Target的孕期用品销售呈现了爆炸性的增长。Andrew Pole的大数据分析技术从孕妇这个细分顾客群开始向其他各种细分客户群推广，从Andrew Pole加入Target的2002年到2010年间，Target的销售额从440亿美元增长到了670亿美元。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;我们可以想象的是，许多孕妇在浑然不觉的情况下成了Target常年的忠实拥泵，许多孕妇产品专卖店也在浑然不知的情况下破产。浑然不觉的背景里，大数据正在推动一股强劲的商业革命暗涌，商家们早晚要面对的一个问题就是：究竟是在浑然不觉中崛起，还是在浑然不觉中灭亡</p>
</blockquote>
<h3><span id="其他故事">其他故事</span></h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/28110315" target="_blank" rel="noopener">Google根据搜索关键字分析流感病毒H1N1</a></li>
<li><a href="https://36kr.com/p/5163514" target="_blank" rel="noopener">2008年金融危机</a></li>
</ul>
<h2><span id="大数据初步学习路线">大数据初步学习路线</span></h2><table>
<thead>
<tr>
<th>技术</th>
<th>工具</th>
</tr>
</thead>
<tbody><tr>
<td>JAVA</td>
<td>面向对象的编程语言</td>
</tr>
<tr>
<td>Linux</td>
<td>类Unix操作系统</td>
</tr>
<tr>
<td>Hadoop生态圈</td>
<td></td>
</tr>
<tr>
<td>1、HDFS</td>
<td>解决存储问题<br>存储极大数目的信息（terabytes or petabytes），将数据保存到大量的节点当中。支持很大单个文件。提供高可靠性，是指一个或多个节点故障，系统仍然可以继续工作<br><br>提供数据快速访问</td>
</tr>
<tr>
<td>2、MapReduce</td>
<td>解决计算问题<br>它有个特点就是不管多大的数据只要给它时间它就能把数据跑完，但是时间可能不是很快所以它叫数据的批处理</td>
</tr>
<tr>
<td>3、Yarn</td>
<td>资源调度器</td>
</tr>
<tr>
<td>4、ZooKeeper</td>
<td>分布式应用程序协调服务<br>一般用于存储一些相互协作的一些信息</td>
</tr>
<tr>
<td>5、Flume</td>
<td>数据采集工具</td>
</tr>
<tr>
<td>6、Hive</td>
<td>基于Hadoop的数据仓库工具</td>
</tr>
<tr>
<td>7、Hbase</td>
<td>分布式应用程序协调服务<br>一般用于存储一些相互协作的一些信息</td>
</tr>
<tr>
<td>8、Sqoop</td>
<td>数据传递工具，如将数据从关系型数据库导入Hive</td>
</tr>
<tr>
<td>Scala</td>
<td>多范式编程语言、面向对象和函数式编程的特性</td>
</tr>
<tr>
<td>Spark</td>
<td>目前企业常用的批处理离线数据/实时计算引擎<br>它是用来弥补基于MapReduce处理数据速度上的缺点，它很是流氓，直接将数据存在内存中<br> <strong>【注意】</strong> MapReduce运行时也是需要将代码数据加载到内存中的，只不过Spark都是基于内存操作</td>
</tr>
<tr>
<td>Flink</td>
<td>目前最火的流式处理框架、既支持流处理、也支持批处理</td>
</tr>
<tr>
<td>Elasticsearch</td>
<td>大数据分布式弹性搜索引擎</td>
</tr>
</tbody></table>
<h2><span id="起源-google-在大数据方面的三大论文-谷歌三宝">起源 Google 在大数据方面的三大论文 （谷歌三宝）</span></h2><p><a href="https://github.com/lyhcc/NoteBook/tree/master/bigdata" target="_blank" rel="noopener">在github大的当前目录下</a><br><a href="https://www.cnblogs.com/javhu/archive/2013/03/25/cyue_hadoop_google.html" target="_blank" rel="noopener">三宝的介绍</a></p>
<h2><span id="hadoop-三大发行版本">Hadoop 三大发行版本</span></h2><ol>
<li>Apache、Cloudera、Hortonworks Apache版本最原始、最基础：适合零基础 大公司在用</li>
<li>Cloudera Cloudera’s DistributionIncluding Apache Hadoop 简称CDH<br>中小型公司用、简单方便、自带可视化 </li>
<li>Hortonworks  文档较好  注：Cloudera 和Hortonworks 在2018年10月，国庆期间宣布合并<h2><span id="硬件要求">硬件要求</span></h2><h4><span id="内存">内存</span></h4></li>
</ol>
<p><strong>最大支持内存查询：</strong>win + R<br><strong>输入</strong>  wmic memphysical get maxcapacity<br><strong>计算</strong> MaxCapacity/1024/1024GB  </p>
<h4><span id="硬盘500g">硬盘:500G+</span></h4><h2><span id="科普">科普</span></h2><blockquote>
<p>根据国际数据公司（IDC）的《数据宇宙》报告显示：2008年全球数量为0.5ZB，2010年为1.2ZB，人类正式进入ZB时代。更为惊人的是，2020年以前全球数据量仍将保持每年40%多的高速增长，大约每两年就翻一倍，这与IT界的摩尔定律极为相似，姑且称之为“大数据爆炸定律”。</p>
</blockquote>

                                                            
                                                                <!-- <h2><span id="什么是大数据">什么是大数据</span></h2><blockquote>
<p>百度百科的定义,大数据（BIG DATA），指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产</p>
</blockquote>
<blockquote>
<p>在目前的业界尚未对大数据由清晰明确的定义, 它的第一次出现是在麦肯锡公司的报告中出现的, 在维基百科上的较为模糊的定义是很难运用软件的手段获取大量的内容信息, 对其处理后整理得出的数据集合。其他计算机学科的学者给出的定义是数据的尺度极为巨大, 常规的数据处理软件无法对数据识别、存储和应用的海量数据信息</p>
</blockquote>
<blockquote>
<p>维基百科的定义，大数据是指无法在可承受的时间范围内用常规软件工具进行捕捉、管理和处理的数据集合。</p>
</blockquote>
<blockquote>
<p>研究机构Gartner定义，“大数据”是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p>
</blockquote>
<h2><span id="数据单位">数据单位</span></h2><p>1MB = 1024KB、1GB = 1024MB<br>1TB = 1024GB、1PB = 1024TB</p>
<h2><span id="大数据的特征">大数据的特征</span></h2><ul>
<li>容量（Volume）：数据的大小决定所考虑的数据的价值和潜在的信息；</li>
<li>种类（Variety）：数据类型的多样性；</li>
<li>速度（Velocity）：指获得数据的速度；</li>
<li>可变性（Variability）：妨碍了处理和有效地管理数据的过程。</li>
<li>真实性（Veracity）：数据的质量</li>
<li>复杂性（Complexity）：数据量巨大，来源多渠道</li>
<li>价值（value）：合理运用大数据，以低成本创造高价值</li>
</ul>
<h2><span id="大数据相关技术">大数据相关技术</span></h2><ol>
<li><strong>数据采集：</strong> OLAP(联机分析处理)和数据挖掘的基础。ETL工具负责将分布的、异构的数据源进行抽取，抽取到中间层，进行清洗、转换、集成，（不过对于负责的逻辑处理不会这么干，用Spark或者其他的进行处理），最后放到数据仓库中存储，如Hive</li>
<li><strong>数据存取：</strong> 关系型数据库、NoSQL(Not Only SQL,泛指非关系型数据库)，SQL等</li>
<li><strong>基础架构：</strong> 云存储、分布式文件存储等</li>
<li><strong>数据处理：</strong> 自然语言处理(Natural Language Processing, NLP)</li>
<li><strong>数据分析：</strong> 假设检验、显著性检验、差异检验、差异分析、相关性分析、T检验、方差分析、卡方分析、偏相关性分析、距离分析、回归分析、简单回归分析、多元回归分析、逐步回归、预测和残差分析、岭回归、Logistic回归分析、曲线估计、因子分析、聚类分析、主成分分析、判别分析、对应分析、快速聚类和聚类法、对应分析、多元对应分析等</li>
<li><strong>数据挖掘：</strong> 分类（Classification）、估计（Estimation）、预测（Prediction)、相关性分析或关联规则（Association）、复杂数据类型挖掘（Text、Web、图形图像、视频、音频等）</li>
<li><strong>模型预测：</strong> 预测模型、机器学习、建模仿真</li>
<li><strong>结果呈现：</strong> 云计算、标签云、关系图等</li>
</ol>
<h2><span id="大数据带来的变革">大数据带来的变革</span></h2><h3><span id="大数据小故事">大数据小故事</span></h3><blockquote>
<p>&emsp;&emsp;最早关于大数据的故事发生在美国第二大的超市塔吉特百货（Target）。孕妇对于零售商来说是个含金量很高的顾客群体。但是他们一般会去专门的孕妇商店而不是在Target购买孕期用品。人们一提起Target，往往想到的都是清洁用品、袜子和手纸之类的日常生活用品，却忽视了Target有孕妇需要的一切。那么Target有什么办法可以把这部分细分顾客从孕妇产品专卖店的手里截留下来呢？</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;为此，Target的市场营销人员求助于Target的顾客数据分析部的高级经理Andrew Pole，要求他建立一个模型，在孕妇第2个妊娠期就把她们给确认出来。在美国出生记录是公开的，等孩子出生了，新生儿母亲就会被铺天盖地的产品优惠广告包围，那时候Target再行动就晚了，因此必须赶在孕妇第2个妊娠期行动起来。如果Target能够赶在所有零售商之前知道哪位顾客怀孕了，市场营销部门就可以早早的给他们发出量身定制的孕妇优惠广告，早早圈定宝贵的顾客资源。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;可是怀孕是很私密的信息，如何能够准确地判断哪位顾客怀孕了呢？Andrew Pole想到了Target有一个迎婴聚会（baby shower）的登记表。Andrew Pole开始对这些登记表里的顾客的消费数据进行建模分析，不久就发现了许多非常有用的数据模式。比如模型发现，许多孕妇在第2个妊娠期的开始会买许多大包装的无香味护手霜；在怀孕的最初20周大量购买补充钙、镁、锌的善存片之类的保健品。最后Andrew Pole选出了25种典型商品的消费数据构建了“怀孕预测指数”，通过这个指数，Target能够在很小的误差范围内预测到顾客的怀孕情况，因此Target就能早早地把孕妇优惠广告寄发给顾客。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;那么，顾客收到这样的广告会不会吓坏了呢？Target很聪明地避免了这种情况，它把孕妇用品的优惠广告夹杂在其他一大堆与怀孕不相关的商品优惠广告当中，这样顾客就不知道Target知道她怀孕了。百密一疏的是，Target的这种优惠广告间接地令一个蒙在鼓里的父亲意外发现他高中生的女儿怀孕了，此事甚至被《纽约时报》报道了，结果Target大数据的巨大威力轰动了全美。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;根据Andrew Pole的大数据模型,Target制订了全新的广告营销方案，结果Target的孕期用品销售呈现了爆炸性的增长。Andrew Pole的大数据分析技术从孕妇这个细分顾客群开始向其他各种细分客户群推广，从Andrew Pole加入Target的2002年到2010年间，Target的销售额从440亿美元增长到了670亿美元。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;我们可以想象的是，许多孕妇在浑然不觉的情况下成了Target常年的忠实拥泵，许多孕妇产品专卖店也在浑然不知的情况下破产。浑然不觉的背景里，大数据正在推动一股强劲的商业革命暗涌，商家们早晚要面对的一个问题就是：究竟是在浑然不觉中崛起，还是在浑然不觉中灭亡</p>
</blockquote>
<h3><span id="其他故事">其他故事</span></h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/28110315" target="_blank" rel="noopener">Google根据搜索关键字分析流感病毒H1N1</a></li>
<li><a href="https://36kr.com/p/5163514" target="_blank" rel="noopener">2008年金融危机</a></li>
</ul>
<h2><span id="大数据初步学习路线">大数据初步学习路线</span></h2><table>
<thead>
<tr>
<th>技术</th>
<th>工具</th>
</tr>
</thead>
<tbody><tr>
<td>JAVA</td>
<td>面向对象的编程语言</td>
</tr>
<tr>
<td>Linux</td>
<td>类Unix操作系统</td>
</tr>
<tr>
<td>Hadoop生态圈</td>
<td></td>
</tr>
<tr>
<td>1、HDFS</td>
<td>解决存储问题<br>存储极大数目的信息（terabytes or petabytes），将数据保存到大量的节点当中。支持很大单个文件。提供高可靠性，是指一个或多个节点故障，系统仍然可以继续工作<br><br>提供数据快速访问</td>
</tr>
<tr>
<td>2、MapReduce</td>
<td>解决计算问题<br>它有个特点就是不管多大的数据只要给它时间它就能把数据跑完，但是时间可能不是很快所以它叫数据的批处理</td>
</tr>
<tr>
<td>3、Yarn</td>
<td>资源调度器</td>
</tr>
<tr>
<td>4、ZooKeeper</td>
<td>分布式应用程序协调服务<br>一般用于存储一些相互协作的一些信息</td>
</tr>
<tr>
<td>5、Flume</td>
<td>数据采集工具</td>
</tr>
<tr>
<td>6、Hive</td>
<td>基于Hadoop的数据仓库工具</td>
</tr>
<tr>
<td>7、Hbase</td>
<td>分布式应用程序协调服务<br>一般用于存储一些相互协作的一些信息</td>
</tr>
<tr>
<td>8、Sqoop</td>
<td>数据传递工具，如将数据从关系型数据库导入Hive</td>
</tr>
<tr>
<td>Scala</td>
<td>多范式编程语言、面向对象和函数式编程的特性</td>
</tr>
<tr>
<td>Spark</td>
<td>目前企业常用的批处理离线数据/实时计算引擎<br>它是用来弥补基于MapReduce处理数据速度上的缺点，它很是流氓，直接将数据存在内存中<br> <strong>【注意】</strong> MapReduce运行时也是需要将代码数据加载到内存中的，只不过Spark都是基于内存操作</td>
</tr>
<tr>
<td>Flink</td>
<td>目前最火的流式处理框架、既支持流处理、也支持批处理</td>
</tr>
<tr>
<td>Elasticsearch</td>
<td>大数据分布式弹性搜索引擎</td>
</tr>
</tbody></table>
<h2><span id="起源-google-在大数据方面的三大论文-谷歌三宝">起源 Google 在大数据方面的三大论文 （谷歌三宝）</span></h2><p><a href="https://github.com/lyhcc/NoteBook/tree/master/bigdata" target="_blank" rel="noopener">在github大的当前目录下</a><br><a href="https://www.cnblogs.com/javhu/archive/2013/03/25/cyue_hadoop_google.html" target="_blank" rel="noopener">三宝的介绍</a></p>
<h2><span id="hadoop-三大发行版本">Hadoop 三大发行版本</span></h2><ol>
<li>Apache、Cloudera、Hortonworks Apache版本最原始、最基础：适合零基础 大公司在用</li>
<li>Cloudera Cloudera’s DistributionIncluding Apache Hadoop 简称CDH<br>中小型公司用、简单方便、自带可视化 </li>
<li>Hortonworks  文档较好  注：Cloudera 和Hortonworks 在2018年10月，国庆期间宣布合并<h2><span id="硬件要求">硬件要求</span></h2><h4><span id="内存">内存</span></h4></li>
</ol>
<p><strong>最大支持内存查询：</strong>win + R<br><strong>输入</strong>  wmic memphysical get maxcapacity<br><strong>计算</strong> MaxCapacity/1024/1024GB  </p>
<h4><span id="硬盘500g">硬盘:500G+</span></h4><h2><span id="科普">科普</span></h2><blockquote>
<p>根据国际数据公司（IDC）的《数据宇宙》报告显示：2008年全球数量为0.5ZB，2010年为1.2ZB，人类正式进入ZB时代。更为惊人的是，2020年以前全球数据量仍将保持每年40%多的高速增长，大约每两年就翻一倍，这与IT界的摩尔定律极为相似，姑且称之为“大数据爆炸定律”。</p>
</blockquote>
 -->
                            </div>
                            
                                    
                                            
                </div>
    </div>

    
        

                

                        


                        </div>
                        




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="" src="https://cdn.jsdelivr.net/gh/lyhcc/Picture_Repository/img/20191026160026.png" alt="lyhcc">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        lyhcc
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        DT Developer
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Hunan,China</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Posts
                    </p>
                    <p class="title has-text-weight-normal">
                        6
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Categories
                    </p>
                    <p class="title has-text-weight-normal">
                        5
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Tags
                    </p>
                    <p class="title has-text-weight-normal">
                        8
                    </p>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/lyhcc" target="_blank">
                Follow</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Github" href="https://github.com/lyhcc">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Facebook" href="https://facebook.com">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Twitter" href="https://twitter.com">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Dribbble" href="https://dribbble.com">
                
                <i class="fab fa-dribbble"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Links
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://hexo.io" target="_blank">
                    <span class="level-left">
                        <span class="level-item">Hexo</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">hexo.io</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://github.com/lyhcc" target="_blank">
                    <span class="level-left">
                        <span class="level-item">lyhcc</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/BigData/">
            <span class="level-start">
                <span class="level-item">BigData</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/BigData/Hadoop/">
            <span class="level-start">
                <span class="level-item">Hadoop</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Hadoop/">
            <span class="level-start">
                <span class="level-item">Hadoop</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/HDFS%E5%BF%AB%E7%85%A7/" style="font-size: 10px;">HDFS快照</a> <a href="/tags/Hadoop-RPC/" style="font-size: 10px;">Hadoop RPC</a> <a href="/tags/Hadoop-%E5%8D%8F%E8%AE%AE/" style="font-size: 10px;">Hadoop 协议</a> <a href="/tags/Hadoop-%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/" style="font-size: 10px;">Hadoop 通信机制</a> <a href="/tags/MapReduce-%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/" style="font-size: 10px;">MapReduce 通信协议</a> <a href="/tags/MapReduce%E4%BB%8B%E7%BB%8D/" style="font-size: 10px;">MapReduce介绍</a> <a href="/tags/hadoop%E5%BA%8F%E5%88%97%E5%8C%96/" style="font-size: 10px;">hadoop序列化</a> <a href="/tags/%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 10px;">什么是大数据</a>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
            <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/post/13550.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Hadoop通信机制和内部协议之协议">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-31T12:41:47.554Z">2019-10-31</time></div>
                    <a href="/post/13550.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">Hadoop通信机制和内部协议之协议</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/post/56192.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Hadoop通信机制和内部协议之RPC">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-30T09:39:49.048Z">2019-10-30</time></div>
                    <a href="/post/56192.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">Hadoop通信机制和内部协议之RPC</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/post/20979.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="hadoop序列化">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-28T10:01:26.105Z">2019-10-28</time></div>
                    <a href="/post/20979.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">hadoop序列化</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/post/5429.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="MapReduce介绍">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-26T10:46:05.391Z">2019-10-26</time></div>
                    <a href="/post/5429.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">MapReduce介绍</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/BigData/">BigData</a> / <a class="has-link-grey -link" href="/categories/BigData/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/post/21534.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="HDFS快照管理">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-26T08:47:04.559Z">2019-10-26</time></div>
                    <a href="/post/21534.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">HDFS快照管理</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/BigData/">BigData</a> / <a class="has-link-grey -link" href="/categories/BigData/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2019/10/">
                <span class="level-start">
                    <span class="level-item">October 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">6</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/HDFS%E5%BF%AB%E7%85%A7/">
                        <span class="tag">HDFS快照</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hadoop-RPC/">
                        <span class="tag">Hadoop RPC</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hadoop-%E5%8D%8F%E8%AE%AE/">
                        <span class="tag">Hadoop 协议</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hadoop-%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/">
                        <span class="tag">Hadoop 通信机制</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/MapReduce-%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/">
                        <span class="tag">MapReduce 通信协议</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/MapReduce%E4%BB%8B%E7%BB%8D/">
                        <span class="tag">MapReduce介绍</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/hadoop%E5%BA%8F%E5%88%97%E5%8C%96/">
                        <span class="tag">hadoop序列化</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%95%B0%E6%8D%AE/">
                        <span class="tag">什么是大数据</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                            




<div class="column is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only has-order-3 column-right ">
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/post/13550.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Hadoop通信机制和内部协议之协议">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-31T12:41:47.554Z">2019-10-31</time></div>
                    <a href="/post/13550.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">Hadoop通信机制和内部协议之协议</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/post/56192.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Hadoop通信机制和内部协议之RPC">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-30T09:39:49.048Z">2019-10-30</time></div>
                    <a href="/post/56192.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">Hadoop通信机制和内部协议之RPC</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/post/20979.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="hadoop序列化">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-28T10:01:26.105Z">2019-10-28</time></div>
                    <a href="/post/20979.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">hadoop序列化</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/post/5429.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="MapReduce介绍">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-26T10:46:05.391Z">2019-10-26</time></div>
                    <a href="/post/5429.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">MapReduce介绍</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/BigData/">BigData</a> / <a class="has-link-grey -link" href="/categories/BigData/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/post/21534.html" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="HDFS快照管理">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-26T08:47:04.559Z">2019-10-26</time></div>
                    <a href="/post/21534.html" class="title has-link-black-ter is-size-6 has-text-weight-normal">HDFS快照管理</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/BigData/">BigData</a> / <a class="has-link-grey -link" href="/categories/BigData/Hadoop/">Hadoop</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2019/10/">
                <span class="level-start">
                    <span class="level-item">October 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">6</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/HDFS%E5%BF%AB%E7%85%A7/">
                        <span class="tag">HDFS快照</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hadoop-RPC/">
                        <span class="tag">Hadoop RPC</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hadoop-%E5%8D%8F%E8%AE%AE/">
                        <span class="tag">Hadoop 协议</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Hadoop-%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6/">
                        <span class="tag">Hadoop 通信机制</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/MapReduce-%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE/">
                        <span class="tag">MapReduce 通信协议</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/MapReduce%E4%BB%8B%E7%BB%8D/">
                        <span class="tag">MapReduce介绍</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/hadoop%E5%BA%8F%E5%88%97%E5%8C%96/">
                        <span class="tag">hadoop序列化</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%95%B0%E6%8D%AE/">
                        <span class="tag">什么是大数据</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
    
    
</div>

                    </div>
                </div>
            </section>
            <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="lyhcc博客" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 John Doe&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
                <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>

<script>
var IcarusThemeSettings = {
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>



    
    
<script src="/js/animation.js"></script>

    
    
<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>

    
    
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/" target="_blank" rel="noopener">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>

    
    <script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>
    
    
<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>

    
    
    
    
    
    
    
    
    
    
    


<script src="/js/main.js" defer></script>

                    
                        <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
                            
</body>

</html>